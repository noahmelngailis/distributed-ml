{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pydataset import data\n",
    "\n",
    "import pyspark\n",
    "import pyspark.ml\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data('tips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(df: pyspark.sql.DataFrame):\n",
    "    return df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "pyspark.ml.feature.RFormula\n",
    "\n",
    "- tip ~ total_bill: predict tip based on total bill\n",
    "- tip ~ total_bill + size: predict tip based on total bill and size\n",
    "- tip ~ .: predict tip based on all the other features in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| [8.77,2.0]|  2.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|[10.27,2.0]| 1.71|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|[10.29,2.0]|  2.6|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|[10.33,3.0]| 1.67|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|[10.34,3.0]| 1.66|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = pyspark.ml.feature.RFormula(formula=\"tip ~ total_bill + size\").fit(train)\n",
    "\n",
    "rf.transform(train).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features and labels columns are the shape/name required for pyspark.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   features|label|\n",
      "+-----------+-----+\n",
      "| [8.77,2.0]|  2.0|\n",
      "|[10.27,2.0]| 1.71|\n",
      "|[10.29,2.0]|  2.6|\n",
      "|[10.33,3.0]| 1.67|\n",
      "|[10.34,3.0]| 1.66|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_input = rf.transform(train).select('features', 'label')\n",
    "train_input.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create, fit, and use the model.\n",
    "\n",
    "**Note**: unlike sklearn, each step produces a new object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_57eeef8c7528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = pyspark.ml.regression.LinearRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------------------+\n",
      "|   features|label|        prediction|\n",
      "+-----------+-----+------------------+\n",
      "| [8.77,2.0]|  2.0|1.8431748565237702|\n",
      "|[10.27,2.0]| 1.71|1.9846902983830195|\n",
      "|[10.29,2.0]|  2.6|1.9865771709411428|\n",
      "|[10.33,3.0]| 1.67|2.1519321354884755|\n",
      "|[10.34,3.0]| 1.66| 2.152875571767537|\n",
      "+-----------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_fit = lr.fit(train_input)\n",
    "lr_fit.transform(train_input).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x11f483650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5083641431094579, 0.925413890798643)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_fit.summary.r2, lr_fit.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coefficientStandardErrors',\n",
       " 'degreesOfFreedom',\n",
       " 'devianceResiduals',\n",
       " 'explainedVariance',\n",
       " 'featuresCol',\n",
       " 'labelCol',\n",
       " 'meanAbsoluteError',\n",
       " 'meanSquaredError',\n",
       " 'numInstances',\n",
       " 'objectiveHistory',\n",
       " 'pValues',\n",
       " 'predictionCol',\n",
       " 'predictions',\n",
       " 'r2',\n",
       " 'r2adj',\n",
       " 'residuals',\n",
       " 'rootMeanSquaredError',\n",
       " 'tValues',\n",
       " 'totalIterations']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(lr_fit.summary) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How do we do on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "|total_bill| tip| sex|smoker|day|  time|size|   features|label|        prediction|\n",
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "|      9.55|1.45|Male|    No|Sat|Dinner|   2| [9.55,2.0]| 1.45|1.9167628862905801|\n",
      "|      9.68|1.32|Male|    No|Sun|Dinner|   2| [9.68,2.0]| 1.32|1.9290275579183815|\n",
      "|      9.94|1.56|Male|    No|Sun|Dinner|   2| [9.94,2.0]| 1.56|1.9535569011739848|\n",
      "|     11.24|1.76|Male|   Yes|Sat|Dinner|   2|[11.24,2.0]| 1.76|2.0762036174520007|\n",
      "+----------+----+----+------+---+------+----+-----------+-----+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_input = rf.transform(test)\n",
    "lr_fit.transform(test_input).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.272225453071824"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.RegressionEvaluator()\n",
    "rmse = evaluator.evaluate(lr_fit.transform(test_input))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|   features|label|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2| [8.77,2.0]|  0.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|[10.27,2.0]|  0.0|\n",
      "|     10.29| 2.6|Female|    No|Sun|Dinner|   2|[10.29,2.0]|  0.0|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|[10.33,3.0]|  0.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|[10.34,3.0]|  0.0|\n",
      "|     12.54| 2.5|  Male|    No|Sun|Dinner|   2|[12.54,2.0]|  0.0|\n",
      "|     13.37| 2.0|  Male|    No|Sat|Dinner|   2|[13.37,2.0]|  0.0|\n",
      "|     13.94|3.06|  Male|    No|Sun|Dinner|   2|[13.94,2.0]|  0.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|[14.78,2.0]|  0.0|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|[14.83,2.0]|  0.0|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|[15.04,2.0]|  0.0|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|[15.42,2.0]|  0.0|\n",
      "|     15.77|2.23|Female|    No|Sat|Dinner|   2|[15.77,2.0]|  0.0|\n",
      "|     16.04|2.24|  Male|    No|Sat|Dinner|   3|[16.04,3.0]|  0.0|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|[16.29,3.0]|  0.0|\n",
      "|     16.31| 2.0|  Male|    No|Sat|Dinner|   3|[16.31,3.0]|  0.0|\n",
      "|     16.93|3.07|Female|    No|Sat|Dinner|   3|[16.93,3.0]|  0.0|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|[16.97,3.0]|  0.0|\n",
      "|     17.46|2.54|  Male|    No|Sun|Dinner|   2|[17.46,2.0]|  0.0|\n",
      "|     17.78|3.27|  Male|    No|Sat|Dinner|   2|[17.78,2.0]|  0.0|\n",
      "|     17.92|4.08|  Male|    No|Sat|Dinner|   2|[17.92,2.0]|  0.0|\n",
      "|     18.29| 3.0|  Male|    No|Sun|Dinner|   2|[18.29,2.0]|  0.0|\n",
      "|     18.35| 2.5|  Male|    No|Sat|Dinner|   4|[18.35,4.0]|  0.0|\n",
      "|     18.69|2.31|  Male|    No|Sat|Dinner|   3|[18.69,3.0]|  0.0|\n",
      "|     19.49|3.51|  Male|    No|Sun|Dinner|   2|[19.49,2.0]|  0.0|\n",
      "|     19.65| 3.0|Female|    No|Sat|Dinner|   2|[19.65,2.0]|  0.0|\n",
      "|     19.82|3.18|  Male|    No|Sat|Dinner|   2|[19.82,2.0]|  0.0|\n",
      "|     20.29|2.75|Female|    No|Sat|Dinner|   2|[20.29,2.0]|  0.0|\n",
      "|     20.29|3.21|  Male|   Yes|Sat|Dinner|   2|[20.29,2.0]|  0.0|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|[20.65,3.0]|  0.0|\n",
      "|     20.69|2.45|Female|    No|Sat|Dinner|   4|[20.69,4.0]|  0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|[21.01,3.0]|  0.0|\n",
      "|      21.7| 4.3|  Male|    No|Sat|Dinner|   2| [21.7,2.0]|  0.0|\n",
      "|     22.23| 5.0|  Male|    No|Sun|Dinner|   2|[22.23,2.0]|  0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|[23.68,2.0]|  0.0|\n",
      "|     24.06| 3.6|  Male|    No|Sat|Dinner|   3|[24.06,3.0]|  0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|[24.59,4.0]|  0.0|\n",
      "|     25.56|4.34|  Male|    No|Sun|Dinner|   4|[25.56,4.0]|  0.0|\n",
      "|     26.41| 1.5|Female|    No|Sat|Dinner|   2|[26.41,2.0]|  0.0|\n",
      "|     28.55|2.05|  Male|    No|Sun|Dinner|   3|[28.55,3.0]|  0.0|\n",
      "|      30.4| 5.6|  Male|    No|Sun|Dinner|   4| [30.4,4.0]|  0.0|\n",
      "|     31.27| 5.0|  Male|    No|Sat|Dinner|   3|[31.27,3.0]|  0.0|\n",
      "|      32.4| 6.0|  Male|    No|Sun|Dinner|   4| [32.4,4.0]|  0.0|\n",
      "|     34.81| 5.2|Female|    No|Sun|Dinner|   4|[34.81,4.0]|  0.0|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|[35.26,4.0]|  0.0|\n",
      "|     39.42|7.58|  Male|    No|Sat|Dinner|   4|[39.42,4.0]|  0.0|\n",
      "|     48.27|6.73|  Male|    No|Sat|Dinner|   4|[48.27,4.0]|  0.0|\n",
      "|      3.07| 1.0|Female|   Yes|Sat|Dinner|   1| [3.07,1.0]|  0.0|\n",
      "|      5.75| 1.0|Female|   Yes|Fri|Dinner|   2| [5.75,2.0]|  0.0|\n",
      "|      7.25| 1.0|Female|    No|Sat|Dinner|   1| [7.25,1.0]|  0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = pyspark.ml.feature.RFormula(formula='time ~ total_bill + size').fit(train)\n",
    "train_input = rf.transform(train)\n",
    "train_input.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pyspark.ml.classification.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fit = lr.fit(train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'areaUnderROC',\n",
       " 'fMeasureByLabel',\n",
       " 'fMeasureByThreshold',\n",
       " 'falsePositiveRateByLabel',\n",
       " 'featuresCol',\n",
       " 'labelCol',\n",
       " 'labels',\n",
       " 'objectiveHistory',\n",
       " 'pr',\n",
       " 'precisionByLabel',\n",
       " 'precisionByThreshold',\n",
       " 'predictionCol',\n",
       " 'predictions',\n",
       " 'probabilityCol',\n",
       " 'recallByLabel',\n",
       " 'recallByThreshold',\n",
       " 'roc',\n",
       " 'totalIterations',\n",
       " 'truePositiveRateByLabel',\n",
       " 'weightedFMeasure',\n",
       " 'weightedFalsePositiveRate',\n",
       " 'weightedPrecision',\n",
       " 'weightedRecall',\n",
       " 'weightedTruePositiveRate']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(lr_fit.summary) if not x.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6430830039525692"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# area under TPR (recall) vs FPR (FP / (FP + TN)) curve\n",
    "# https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "lr_fit.summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5809716599190283"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.BinaryClassificationEvaluator()\n",
    "test_auc = evaluator.evaluate(lr_fit.transform(rf.transform(test)))\n",
    "test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---+\n",
      "|prediction|0.0|1.0|\n",
      "+----------+---+---+\n",
      "|       0.0| 38| 13|\n",
      "+----------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for the test data\n",
    "(lr_fit.transform(test_input)\n",
    " .select('time', 'total_bill', 'size', 'label', 'probability', 'prediction')\n",
    " .groupby('prediction') # predicted == rows\n",
    " .pivot('label') # actual values are columns\n",
    " .count()\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many other preprocessing steps\n",
    "# dir(pyspark.ml.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
